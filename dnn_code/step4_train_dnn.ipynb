{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84a68607",
   "metadata": {},
   "source": [
    "Starting with importing all packages needed for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d06875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 21:25:39.644373: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shap\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras import regularizers\n",
    "import pickle\n",
    "\n",
    "    \n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b49fa13",
   "metadata": {},
   "source": [
    "Reading in the name of all environmental variables and creating a new file which will display all the metrics of the best performing model for each species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eebb65e-954d-4f38-a8b8-60d8627f46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir=('/Users/maddie/Projects/fishpredict')\n",
    "#create text file to store results in and close again:\n",
    "with open(file_dir+'/results/DNN_performance/DNN_eval.txt','w+') as file:\n",
    "    file.write(\"Species\"+\"\\t\"+\"Test_loss\"+\"\\t\"+\"Test_acc\"+\"\\t\"+\"Test_tpr\"+\"\\t\"+\"Test_AUC\"+\"\\t\"+\"Test_LCI95%\"+\"\\t\"+\"Test_UCI95%\"+\"\\t\"+\"occ_samples\"+\"\\t\"+\"abs_samples\"+\"\\n\")\n",
    "    file.close()\n",
    "#access file with list of taxa names\n",
    "taxa=pd.read_csv(file_dir+'/data/modified_data/gbif_filtered/taxa_list.txt',header=None)\n",
    "taxa.columns=[\"taxon\"] \n",
    "\n",
    "###column variable names\n",
    "with open(file_dir+'/data/data_raw/bio_oracle/variable_list.txt') as f:\n",
    "      new_cols = f.readlines()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5924a2e6",
   "metadata": {},
   "source": [
    "Constructing and testing the model for each species. \n",
    "\n",
    "* For every species that I had, I constructed and trained the model 5 times, and saved the model with the best metrics for each species. \n",
    "  \n",
    "* During each of the 5 runs per species, there were 40 epochs per model, using the ADAM optimizer and a learning rate of 0.001. \n",
    "  \n",
    "* All species data was split 85/15 for training and 'evaluating' (valiation, but it is shown as testing here). \n",
    "  \n",
    "* The model with the best AUC and other metrics was saved in an .h5 model which was used for both testing in step 5 and for predicitons in the web app. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be66969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.8004\n",
      "180/180 [==============================] - 0s 944us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Citharichthys_sordidus.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Citharichthys_sordidus.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.8004\n",
      "180/180 [==============================] - 0s 929us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Citharichthys_sordidus.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Citharichthys_sordidus.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "180/180 [==============================] - 0s 949us/step - loss: 0.4353 - accuracy: 0.8040\n",
      "180/180 [==============================] - 0s 834us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Citharichthys_sordidus.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Citharichthys_sordidus.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4\n",
      "180/180 [==============================] - 0s 968us/step - loss: 0.4437 - accuracy: 0.8004\n",
      "180/180 [==============================] - 0s 834us/step\n",
      "run 5\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8004\n",
      "180/180 [==============================] - 0s 910us/step\n",
      "run 1\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7919\n",
      "87/87 [==============================] - 0s 906us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Engraulis_mordax.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Engraulis_mordax.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7631\n",
      "87/87 [==============================] - 0s 960us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Engraulis_mordax.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Engraulis_mordax.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7969\n",
      "87/87 [==============================] - 0s 969us/step\n",
      "run 4\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7670\n",
      "87/87 [==============================] - 0s 914us/step\n",
      "run 5\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.8041\n",
      "87/87 [==============================] - 0s 911us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Engraulis_mordax.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Engraulis_mordax.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7923\n",
      "70/70 [==============================] - 0s 935us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Paralichthys_californicus.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Paralichthys_californicus.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7923\n",
      "70/70 [==============================] - 0s 963us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Paralichthys_californicus.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Paralichthys_californicus.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7923\n",
      "70/70 [==============================] - 0s 1ms/step\n",
      "run 4\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7923\n",
      "70/70 [==============================] - 0s 978us/step\n",
      "run 5\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7923\n",
      "70/70 [==============================] - 0s 948us/step\n",
      "run 1\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7835\n",
      "98/98 [==============================] - 0s 1ms/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Scomber_japonicus.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Scomber_japonicus.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7886\n",
      "98/98 [==============================] - 0s 941us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Scomber_japonicus.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Scomber_japonicus.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7892\n",
      "98/98 [==============================] - 0s 942us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Scomber_japonicus.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Scomber_japonicus.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 4\n",
      "98/98 [==============================] - 0s 984us/step - loss: 0.5125 - accuracy: 0.7886\n",
      "98/98 [==============================] - 0s 872us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Scomber_japonicus.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Scomber_japonicus.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 5\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.7854\n",
      "98/98 [==============================] - 0s 896us/step\n",
      "run 1\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.7264\n",
      "235/235 [==============================] - 0s 918us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Thunnus_alalunga.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Thunnus_alalunga.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "235/235 [==============================] - 0s 943us/step - loss: 0.5658 - accuracy: 0.7368\n",
      "235/235 [==============================] - 0s 878us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Thunnus_alalunga.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Thunnus_alalunga.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "235/235 [==============================] - 0s 956us/step - loss: 0.5777 - accuracy: 0.7027\n",
      "235/235 [==============================] - 0s 888us/step\n",
      "run 4\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7305\n",
      "235/235 [==============================] - 0s 901us/step\n",
      "run 5\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7366\n",
      "235/235 [==============================] - 0s 889us/step\n",
      "run 1\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.6468 - accuracy: 0.6388\n",
      "472/472 [==============================] - 0s 895us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Xiphias_gladius.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Xiphias_gladius.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.6462 - accuracy: 0.6332\n",
      "472/472 [==============================] - 0s 919us/step\n",
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Xiphias_gladius.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maddie/Projects/fishpredict/deploy_webapp/saved_models/Xiphias_gladius.pkl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 3\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.6446 - accuracy: 0.6337\n",
      "472/472 [==============================] - 1s 969us/step\n",
      "run 4\n",
      "472/472 [==============================] - 1s 937us/step - loss: 0.6434 - accuracy: 0.6318\n",
      "472/472 [==============================] - 0s 931us/step\n",
      "run 5\n",
      "472/472 [==============================] - 1s 1ms/step - loss: 0.6435 - accuracy: 0.6341\n",
      "472/472 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "var_names=[]\n",
    "\n",
    "for item in new_cols:\n",
    "    item=item.replace(\"\\n\",\"\")\n",
    "    var_names.append(item) \n",
    "\n",
    "    \n",
    "for species in taxa[\"taxon\"][:]:\n",
    "   \n",
    "    #open dataframe and rename columns\n",
    "    spec = species\n",
    "    table = pd.read_csv(file_dir +\"/data/modified_data/spec_ppa_env/%s_env_dataframe.csv\"%spec)         \n",
    "    table.rename(columns=dict(zip(table.columns[1:10], var_names)),inplace=True)\n",
    "    \n",
    "    ####################################\n",
    "    #  filter dataframe for training   #\n",
    "    ####################################\n",
    "   \n",
    "    # drop any row with no-data values\n",
    "    table = table.dropna(axis=0, how=\"any\")\n",
    "\n",
    "\n",
    "    # make feature vector\n",
    "    band_columns = [column for column in table.columns[1:10]]\n",
    "    \n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for _, row in table.iterrows():\n",
    "        x = row[band_columns].values\n",
    "        x = x.tolist()\n",
    "        x.append(row[\"present/pseudo_absent\"])\n",
    "        X.append(x)\n",
    "\n",
    "    df = pd.DataFrame(data=X, columns=band_columns + [\"presence\"])\n",
    "    df.to_csv(\"filtered.csv\", index=None)\n",
    "\n",
    "    # extract n. of occ. and abs. samples\n",
    "    occ_len=int(len(df[df[\"presence\" ]==1]))\n",
    "    abs_len=int(len(df[df[\"presence\" ]==0]))\n",
    "    \n",
    "    ####################################\n",
    "    #  Numpy feature and target array  #\n",
    "    ####################################\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    band_columns = [column for column in df.columns[:-1]]\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(row[band_columns].values.tolist())\n",
    "        y.append([1 - row[\"presence\"], row[\"presence\"]])\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    y = np.vstack(y)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ####################################\n",
    "    #    Split training and test set   #\n",
    "    ####################################\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y,random_state=42)\n",
    "    \n",
    "    test_set=pd.DataFrame(X_test)\n",
    "    test_set.rename(columns=dict(zip(test_set.columns[0:9], var_names)),inplace=True)\n",
    "    \n",
    "    shuffled_X_train=X_train.copy()\n",
    "    np.random.shuffle(shuffled_X_train)\n",
    "    shuffled_X_train=shuffled_X_train[:1000] # random subsample from test set for feature importance\n",
    "    \n",
    "    shuffled_X_test=X_test.copy()\n",
    "    np.random.shuffle(shuffled_X_test)\n",
    "    shuffled_X_test=shuffled_X_test[:1000] # random subsample from test set for feature importance\n",
    "    \n",
    "    ####################################\n",
    "    #      Training and testing        #\n",
    "    ####################################\n",
    "    \n",
    "    # prepare metrics\n",
    "    test_loss=[]\n",
    "    test_acc=[]\n",
    "    test_AUC=[]\n",
    "    test_tpr=[]\n",
    "    test_uci=[]\n",
    "    test_lci=[]\n",
    "\n",
    "   \n",
    "    Best_model_AUC=[0]\n",
    "    \n",
    "    # Five repetitions\n",
    "    for i in range(1,6):\n",
    "        print(\"run %s\"%i)\n",
    "        ###################\n",
    "        # Construct model #\n",
    "        ###################\n",
    "        batch_size = 75\n",
    "        num_classes = 2\n",
    "        epochs = 40\n",
    "\n",
    "        num_inputs = X.shape[1]  # number of features\n",
    "\n",
    "\n",
    "        model = Sequential()\n",
    "        layer_1 = Dense(100, activation='relu',input_shape=(num_inputs,))#, kernel_regularizer=regularizers.l1(0.000001))\n",
    "        layer_2 = Dense(50, activation='relu', input_shape=(num_inputs,))#, kernel_regularizer=regularizers.l1(0.000001))\n",
    "        layer_3 = Dense(25, activation='relu', input_shape=(num_inputs,))#, kernel_regularizer=regularizers.l1(0.0000001))\n",
    "        layer_4 = Dense(10, activation='relu', input_shape=(num_inputs,))#, kernel_regularizer=regularizers.l1(0.00000001))\n",
    "\n",
    "\n",
    "        model.add(layer_1)\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(layer_2)\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(layer_3)\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(layer_4)\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "        out_layer = Dense(num_classes, activation=None)\n",
    "        model.add(out_layer)\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        #model.summary()\n",
    "\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics =['accuracy'])\n",
    "        \n",
    "        ###############\n",
    "        # Train model #\n",
    "        ###############\n",
    "        \n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        #history = model.fit(X_train, y_train, epochs=epochs, batch_size = batch_size, verbose=0)\n",
    "        #shap_values = shap.Explainer(model)(X_test)\n",
    "\n",
    "        ##############\n",
    "        # Test model #\n",
    "        ##############\n",
    "        score = model.evaluate(X_test, y_test, verbose=1)\n",
    "        predictions = model.predict(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:, 1], predictions[:, 1])\n",
    "        len_tpr=int(len(tpr)/2)\n",
    "      \n",
    "\n",
    "        #################\n",
    "        # Append scores #\n",
    "        #################\n",
    "        test_loss.append(score[0])\n",
    "        test_acc.append(score[1])\n",
    "        test_AUC.append(roc_auc_score(y_test[:, 1], predictions[:, 1]))\n",
    "        test_tpr.append(tpr[len_tpr])\n",
    "        AUC = roc_auc_score(y_test[:, 1], predictions[:, 1])\n",
    "\n",
    "        ###############################\n",
    "        # Create confidence intervals #\n",
    "        ###############################\n",
    "        n_bootstraps=1000\n",
    "        y_pred=predictions[:,1]\n",
    "        y_true=y_test[:,1]\n",
    "        rng_seed=42\n",
    "        bootstrapped_scores =[]\n",
    "\n",
    "\n",
    "        rng=np.random.RandomState(rng_seed)\n",
    "        for i in range (n_bootstraps):\n",
    "            #bootstrap by sampling with replacement on prediction indices\n",
    "            indices = rng.randint(0,len(y_pred)-1,len(y_pred))\n",
    "            if len (np.unique(y_true[indices])) <2:\n",
    "                continue\n",
    "\n",
    "            score = roc_auc_score(y_true[indices],y_pred[indices])\n",
    "            bootstrapped_scores.append(score)\n",
    "\n",
    "        sorted_scores=np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "\n",
    "        ci_lower=sorted_scores[int(0.05*len(sorted_scores))]\n",
    "        ci_upper=sorted_scores[int(0.95*len(sorted_scores))]\n",
    "     \n",
    "        test_lci.append(ci_lower)\n",
    "        test_uci.append(ci_upper)\n",
    "       \n",
    "    \n",
    "        ##############################################################\n",
    "        # Selection of best model across runs and feature importance #\n",
    "        ##############################################################\n",
    "    \n",
    "        #determine whether new model AUC is higher\n",
    "        if AUC > Best_model_AUC[0]:\n",
    "            # if yes save model to disk / overwrite previous model\n",
    "            Best_model_AUC[0]=AUC\n",
    "            model.save(file_dir+'/deploy_webapp/saved_models/{}.pkl'.format(spec))\n",
    "            #model_json=model.to_json()\n",
    "            #with open (file_dir+'/results/fish/{}/{}_model.json'.format(spec,spec),'w') as json_file:\n",
    "            #    json_file.write(model_json)\n",
    "            #model.save_weights(file_dir+'/results/fish/{}/{}_model.h5'.format(spec,spec))\n",
    "            #if yes, save a figure of shap feature value impact    \n",
    "            \n",
    "        #    if int(len(X_train)) > 5000:           \n",
    "        #        explainer=shap.DeepExplainer(model,shuffled_X_train)\n",
    "        #        test_set=pd.DataFrame(shuffled_X_test)\n",
    "        #        test_set.rename(columns=dict(zip(test_set.columns[0:40], var_names)),inplace=True)\n",
    "                \n",
    "        #        shap_values=explainer.shap_values(shuffled_X_test)\n",
    "        #        fig=shap.summary_plot(shap_values[1],test_set,show=False)\n",
    "        #        plt.savefig(file_dir+'/results/fish/{}/{}_feature_impact'.format(spec,spec),bbox_inches=\"tight\")\n",
    "        #        plt.close()\n",
    "            \n",
    "        #    else:\n",
    "        #        explainer=shap.DeepExplainer(model,X_train)\n",
    "        #        shap_values=explainer.shap_values(X_test)\n",
    "        #        fig=shap.summary_plot(shap_values[1],test_set,show=False)\n",
    "        #        plt.savefig(file_dir+'/results/fish/{}/{}_feature_impact'.format(spec,spec),bbox_inches=\"tight\")\n",
    "        #        plt.close()\n",
    "            \n",
    "\n",
    "\n",
    "    # Model output metrics averaged across five runs to be written to file\n",
    "#    avg_loss= sum(test_loss)/len(test_loss)\n",
    "#    avg_acc = sum(test_acc)/len(test_acc)\n",
    "#    avg_AUC = sum(test_AUC)/len(test_AUC)\n",
    "#    avg_tpr = sum(test_tpr)/len(test_tpr)\n",
    "#    avg_lci = sum(test_lci)/len(test_lci)\n",
    "#    avg_uci = sum(test_uci)/len(test_uci)\n",
    "\n",
    "    # Write to file\n",
    "#    with open(file_dir+'/results/DNN_performance/DNN_eval.txt','a') as file:\n",
    "#        file.write(spec+\"\\t\"+str(avg_loss)+\"\\t\"+str(avg_acc)+\"\\t\"+str(avg_tpr)+\"\\t\"+str(avg_AUC)+\"\\t\"+str(avg_lci)+\"\\t\"+str(avg_uci)+\"\\t\"+str(occ_len)+\"\\t\"+str(abs_len)+\"\\n\")       \n",
    "\n",
    "\n",
    "    #Next species!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
